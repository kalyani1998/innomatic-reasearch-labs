# -*- coding: utf-8 -*-
"""Exploratory Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vConBLLd1XnZDHrrzJ6g10NuRsbpvA8i
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import datetime as dt

pwd

df = pd.read_excel('aspiring_minds_employability_outcomes_2015.xlsx')

df.head()

pd.set_option('display.max_columns', None)

df.drop('Unnamed: 0', inplace=True, axis=1)

df.head()

df = df.rename(columns = {"10percentage":"Class10_percentage"})
df = df.rename(columns = {"12percentage":"Class12_percentage"})
df = df.rename(columns = {"12graduation":"Class12_Passout"})

shape = df.shape
print(f'Dataset having {shape[0]} rows and {shape[1]} columns')
# print(f'Dataset having {shape[1]} columns')

np.round(df.describe())

np.round(df.describe().transpose())

df.info()

df.head()

int_col = df.select_dtypes(include=['int64','float64']).columns
cat_col = df.select_dtypes(include=['object']).columns
datet_col = df.select_dtypes(include=['datetime64[ns]']).columns
print('Int and float col name :')
print(int_col)
print()
print('Categorical col name :')
print(cat_col)
print()
print('Date Time col name :')
print(datet_col)

#converting date column to datetime type
#and fetching year,month and day from column
# df["DOJ"]=pd.to_datetime(df["DOJ"])
df["DOL"].replace("present",dt.datetime.today(),inplace=True)
df["DOL"]=pd.to_datetime(df["DOL"])
df["Year"]=pd.to_datetime(df["DOL"]).dt.year
df["Month"]=pd.to_datetime(df["DOL"]).dt.month
df["Day"]=pd.to_datetime(df["DOL"]).dt.day

# replacing -1 value present in dataframe to 0

df.replace(to_replace=-1, value=0, inplace=True)

# we can see in 10board and 12board columns values is not stable, so i'am changing all values to only state board,cbse board,icse board
df['10board'].value_counts()

df['10board'].unique()

# df.replace(to_replace=-1, value=0, inplace=True)
df['10board'].replace([ 'cbse', 'cbse[gulf zone]','icse board , new delhi', 'cbse board','central board of secondary education'], 'cbse',inplace=True)
df['10board'].replace("cicse","icse",inplace=True)

board10_uniqueval = df['10board'].unique()
board10_append = []
for i in board10_uniqueval:
  if i == 'cbse' or i == 'icse':
    continue
  else:
    board10_append.append(i)

board10_append

for j in board10_append:
  df['10board'].replace(j, 'state',inplace=True)

df['10board'].unique()

df['12board'].value_counts()

df['12board'].unique()

df['12board'].replace(['all india board','central board of secondary education, new delhi', 'cbese'], 'cbse',inplace=True)
df['12board'].replace(['isc', 'isc board', 'isce', 'cicse','isc board , new delhi'], 'icse',inplace=True)

board12_uniqueval = df['12board'].unique()
board12_append = []
for i in board12_uniqueval:
  if i == 'cbse' or i == 'icse':
    continue
  else:
    board12_append.append(i)

board12_append

for j in board12_append:
  df['12board'].replace(j,'state',inplace=True)
# data['10 board'].replace(0,'n/a',inplace=True)

df['12board'].unique()

df.shape

df.isnull().sum()

df[int_col].head()

df[cat_col].head()

df[datet_col].head()

# Univariate Analysis on Salary column

sns.set_style("darkgrid")
plt.figure(figsize=(8,6))
sns.distplot(df['Salary'])
plt.axvline(df['Salary'].mean(),color='black', label='Mean')
plt.title("Distribution of Salary")
plt.legend(shadow=True,fontsize="larger")

skew = df['Salary'].skew()
kurt = df['Salary'].kurt()
print('Skewness:{}'.format(round(skew,2)))
print('Kurtosis:{}'.format(round(kurt,2)))

plt.show()

# Univariate Analysis on Sa10percentage column

sns.set_style("darkgrid")
plt.figure(figsize=(8,6))
sns.distplot(df['Class10_percentage'])
plt.axvline(df['Class10_percentage'].mean(), color="blue", label="Mean")
plt.title("distribution of Class10_percentage")
plt.legend(shadow=True,fontsize="larger")

skew = df['Class10_percentage'].skew()
kurt = df['Class10_percentage'].kurt()
print('Skewness:{}'.format(round(skew,2)))
print('Kurtosis:{}'.format(round(kurt,2)))

# Univariate Analysis on Sa10percentage column

sns.set_style("darkgrid")
plt.figure(figsize=(8,6))
sns.distplot(df['Class12_percentage'])
plt.axvline(df['Class12_percentage'].mean(), color="blue", label="Mean")
plt.title("distribution of Class12_percentage")
plt.legend(shadow=True,fontsize="larger")

skew = df['Class12_percentage'].skew()
kurt = df['Class12_percentage'].kurt()
print('Skewness:{}'.format(round(skew,2)))
print('Kurtosis:{}'.format(round(kurt,2)))

#year of joining
(df['DOJ'].dt.year).value_counts().plot(kind='bar')

# Bar graph of Birth Year
(df['DOB'].dt.year).value_counts().plot(kind='bar')

board10_grouped = df.groupby(by='10board').size()
board10_grouped.plot.bar()

board12_grouped = df.groupby(by='12board').size()
board12_grouped.plot.bar()

class12passout_grouped = df.groupby(by='Class12_Passout').size()
class12passout_grouped.plot.bar()

(df['Gender']).value_counts().plot(kind='bar')

top_fields=list(df.sort_values("Salary",ascending=False)["Designation"].unique())[:20]
print(top_fields)

top_designation=df[df["Designation"].isin(top_fields)]

top_designation.groupby(["Designation"])["Salary"].describe().sort_values("max",ascending=False)

plt.figure(figsize=(15,5))
top_designation["Designation"].value_counts().plot(kind="bar")

plt.figure(figsize=(35,15))
sns.countplot(x="Designation",hue="Gender",data=top_designation)
plt.xticks(fontsize=32,rotation=90)
plt.yticks(fontsize=32)

#lets add exp column to dataset
top_designation["Exp"]=(top_designation["DOL"]).dt.year - (top_designation["DOJ"]).dt.year

top_designation.head()

plt.figure(figsize=(35,15))

sns.countplot(df.Gender,hue=df.Specialization)
plt.show()

def outliers_iqr(df,col):    
    q1 = df[col].quantile(0.25)
    q3 = df[col].quantile(0.75)
    iqr = q3 - q1

    lb = q1 - (1.5*iqr)
    ub = q3 + (1.5*iqr)
    outliers = []
    for val in df[col]:
        if val < lb or val > ub:
            outliers.append(val)

    return outliers,len(outliers)

outliers_iqr(df, 'Salary')

sns.boxplot(x='Salary', y = 'Gender', data=df)
plt.suptitle('Salary levels by gender')

df.head()

#Salary distribution for each designation
plt.figure(figsize=(35,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.histplot(x="Salary",data=top_designation[top_designation["Designation"]==top_fields[j]],bins=10,hue="Gender")
    plt.title(top_fields[j])

i=10
plt.figure(figsize=(35,10))
for j in range(len(top_fields[10:])):
    plt.subplot(str(25)+str(j))
    sns.histplot(x="Salary",data=top_designation[top_designation["Designation"]==top_fields[i]],bins=10,hue="Gender")
    plt.title(top_fields[i])
    i=i+1

# Doing same with Box plot and see the median salary
plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[top_designation["Designation"]==top_fields[j]])
    plt.title(top_fields[j])

i=10
plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[top_designation["Designation"]==top_fields[i]])
    plt.title(top_fields[i])
    i=i+1

# lets check for individual gender
# for male

plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[(top_designation["Designation"]==top_fields[j]) & (top_designation["Gender"]=="m")])
    plt.title(top_fields[j])

i=10
plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[(top_designation["Designation"]==top_fields[i]) & (top_designation["Gender"]=="m")])
    plt.title(top_fields[i])
    i=i+1

# for female
plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[(top_designation["Designation"]==top_fields[j]) & (top_designation["Gender"]=="f")])
    plt.title(top_fields[j])

i=10
plt.figure(figsize=(20,10))
for j in range(len(top_fields[:10])):
    plt.subplot(str(25)+str(j))
    sns.boxplot(x="Salary",data=top_designation[(top_designation["Designation"]==top_fields[i]) & (top_designation["Gender"]=="f")])
    plt.title(top_fields[i])
    i=i+1

top_designation.head(1)

# Lets Look Salary By Jib City like which State offers more salary
plt.figure(figsize=(100,20))
sns.barplot(x="JobCity",y="Salary",hue="Gender",data=top_designation)
plt.xticks(fontsize=68,rotation=90)
plt.yticks(fontsize=68)

# Lets Check the Degree
sns.countplot(x="Degree",hue="Gender",data=top_designation)

# Lets Check In Which State most aspirants are working.
plt.figure(figsize=(55,15))
sns.countplot(x="JobCity",data=top_designation,hue="Gender")
plt.xticks(fontsize=38,rotation=90)
plt.yticks(fontsize=38)

# Lets Check from which region most aspirants are from
plt.figure(figsize=(55,15))
sns.countplot(x="CollegeState",data=top_designation,hue="Gender")
plt.xticks(fontsize=42,rotation=90)
plt.yticks(fontsize=42)

top_designation["SAL"]=top_designation["Salary"].apply(lambda x:">=500K" if x>=5 else "<500K")
top_designation["EXPR"]=top_designation["Exp"].apply(lambda x:str(x))
top_designation["GPA"]=top_designation["collegeGPA"].apply(lambda x:str(x))
np.random.seed(1)
mindSample=top_designation[['Designation', 'JobCity', 'Gender','Degree', 'Specialization',"GPA","SAL"]].groupby("Gender").sample(200)

top_designation.head()

top_designation["Age"]=pd.to_datetime(top_designation["DOL"]).dt.year-pd.to_datetime(top_designation["DOB"]).dt.year
plt.figure(figsize=(15,5))
plt.subplot(131)
sns.scatterplot(x="Exp",y="Salary",data=top_designation,hue="Gender")
plt.subplot(132)
sns.scatterplot(x="Age",y="Salary",data=top_designation,hue="Gender")
plt.subplot(133)
sns.scatterplot(x="collegeGPA",y="Salary",data=top_designation,hue="Gender")

# Lets Check the Degree
sns.countplot(x="Degree",hue="Gender",data=top_designation)

plt.figure(figsize=(50,20))
sns.countplot(x="Specialization",hue="Degree",data=top_designation)
plt.xticks(fontsize=42,rotation=90)
plt.yticks(fontsize=42)
plt.legend(fontsize=35)

from scipy import stats as st

# Lets Test a hypothesis for sw engg field to check whether of not the salary is >=300K,Age>=27,Exp=5.
np.random.seed(1)
sw_eng_samp=top_designation[(top_designation["Designation"]=="software engineer")].sample(100)
saltest=np.round(st.ttest_1samp(sw_eng_samp["Salary"],popmean=3)[1],2)
exptest=np.round(st.ttest_1samp(sw_eng_samp["Exp"],popmean=4)[1],2)
agetest=np.round(st.ttest_1samp(sw_eng_samp["Age"],popmean=27)[1],2)
if saltest<0.05:
    print("We Reject the null claim and state that the AVG salary for Sw engineers is not 300K")
else:
    print("We accept the null claim and state that the AVG salary for Sw engineers is min 300K")
if agetest<0.05:
    print("We Reject the null claim and state that the AVG age for Sw engineers is not 27")
else:
    print("We accept the null claim and state that the AVG age for Sw engineers is 27")
if exptest<0.05:
    print("We Reject the null claim and state that the AVG exp for Sw engineers is not 4 Yrs")
else:
    print("We accept the null claim and state that the AVG exp for Sw engineers is 4 Yrs")

top_designation[(top_designation["Designation"]=="software engineer") & (top_designation["Gender"]=="m")][["Age","Salary","Exp"]].mean()

df.head(1)

# Correlation between the feature using pairplot

plt.figure(figsize=(20,15))
data = df[['Salary','Class10_percentage','Class12_percentage','collegeGPA', 'conscientiousness','agreeableness','extraversion','nueroticism','openess_to_experience']]
sns.pairplot(data)
plt.show()

plt.figure(figsize=(20,15))
data = top_designation[['Salary','Exp']]
sns.pairplot(data)
plt.show()

# hypothesis testing

df.head()

# Normalize Salary for Better Visualization

df['nor_sal']=df['Salary']/100000

print('Average Salary :')
print('Programmer Analyst :',round(df['nor_sal'][(df['GraduationYear']==2014) & (df['Designation']=='programmer analyst') & (df['Specialization']=='computer science & engineering')].mean(), 2))
print('Software Engineer :',round(df['nor_sal'][(df['GraduationYear']==2014) & (df['Designation']=='software engineer')  & (df['Specialization']=='computer science & engineering')].mean(),2))
print('Hardware Engineer :',round(df['nor_sal'][(df['GraduationYear']==2014) &(df['Designation']=='hardware engineer')  & (df['Specialization']=='computer science & engineering')].mean(), 2))
print('Associate Engineer :',round(df['nor_sal'][(df['GraduationYear']==2014) &(df['Designation']=='associate engineer')  & (df['Specialization']=='computer science & engineering')].mean(), 2))

# Sample Data of required employees

sample = np.array([3.02,3.4,0,3.32])
sample

# mean
sample_size = len(sample)
sample_mean = np.mean(sample)
sample_mean

# Standard Deviation
import math
sample_std = math.sqrt(sum([(i-sample_mean)**2 for i in sample]) / 3)
print('Sample Standard Deviation :', sample_std)

pop_mean = 2.75
sample_mean = 2.43
sample_std = 1.63
sample_size = 4

# Calling T-score Function
def t_score(pop_mean, sample_mean, sample_std, sample_size):
    numerator = sample_mean - pop_mean
    denomenator = sample_std / (sample_size**0.5)
    return numerator / denomenator


t_sc = t_score(pop_mean, sample_mean, sample_std, sample_size)
print('t-score :', t_sc)

# Two Tail - Deciding the Significance Level & Calculating the t-critical value
from scipy.stats import t
confidence_level = 0.95
alpha = 1 - confidence_level
t_critical = t.ppf(1-alpha/2, df = 3)
print('t_critical :', t_critical)

# Visualizing the Sampling Distribution with Rejection Regions
from scipy.stats import norm
# Defining the x min & x max
x_min = 2
x_max =6

# Defining the Sampling Distribution mean & std
mean = pop_mean
std = sample_std / (sample_size**0.5)

# Ploting the graph and setting the x limits
x = np.linspace(x_min, x_max, 100)
y = norm.pdf(x, mean, std)
plt.xlim(x_min, x_max)
plt.plot(x, y)

# Computing the left and right critical values of Two tailed Test
t_critical_left = pop_mean + (-t_critical * std)
t_critical_right = pop_mean + (t_critical * std)

print('t_critical_left :', t_critical_left)
print('t_critical_right :', t_critical_right)

# Shading the left rejection region
x_left = np.linspace(x_min, t_critical_left, 100)
y_left = norm.pdf(x_left, mean, std)
plt.fill_between(x_left, y_left, color='red')

# Shading the right rejection region
x_right = np.linspace(t_critical_right, x_max, 100)
y_right = norm.pdf(x_right, mean, std)
plt.fill_between(x_right, y_right, color='red')

plt.scatter(sample_mean, 0)
plt.annotate("x_bar", (sample_mean, 0.1))

# Compairing the Table Value and T-score value
# Conclusion using t-test
if np.abs(t_sc) > t_critical:
    print("Reject Null Hypothesis")
else:
    print("Fail to reject Null Hypothesis")

# Conclusion using p-test
p_value = 2 * (1.0 - norm.cdf(np.abs(t_sc)))

print("p_value = ", p_value)

if p_value < alpha:
    print("Reject Null Hypothesis")
else:
    print("Fail to reject Null Hypothesis")

# Column standardization using MinMax Scaler
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

# Standardizing Salary Column

scaled_sal = scaler.fit_transform(df['Salary'].values.reshape(-1,1))
print(scaled_sal[:20])

# Standardizing 10th percent Column
scaled_10 = scaler.fit_transform(df['Class10_percentage'].values.reshape(-1,1))
print(scaled_10[:20])

# Standardizing 12th percent Column
scaled_12 = scaler.fit_transform(df['Class12_percentage'].values.reshape(-1,1))
print(scaled_12[:20])

# One-hot Encoding of Gender column
dummies = pd.get_dummies(df[['Gender']])
dummies

df1 = pd.concat([df,dummies],axis='columns')
df1.head()

finaldf = df1.drop(['Gender','Gender_f'],axis='columns')
finaldf